{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Class 16: Random Forest and Boosting\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# from pathlib import Path\n",
    "import sys\n",
    "from patsy import dmatrices\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.pardir, 'data', 'airbnb_london_workfile_adj_book.csv') # this will produce a path with the right syntax for your operating system\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA IMPORT - FROM FILE\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We focus on normal apartments, n < 8\n",
    "df = df[df.n_accommodates < 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy a variable - purpose later, see at variable importance\n",
    "df['n_accommodates_copy'] = df['n_accommodates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***numerical variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too long to display and read\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.price.describe(percentiles = [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99]).map('{:,.1f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***categorical variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.f_room_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.f_property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.f_number_of_reviews.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.f_neighbourhood_cleansed.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***split train and test***\n",
    "- train is where we do it all, incl CV\n",
    "\n",
    "- first pick a smaller than usual training set so that models run faster and check if works\n",
    "- if works, start anew without these two lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_holdout = train_test_split( df, train_size=0.7, random_state = 20250224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.shape, df_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic variables inc neighbourhood\n",
    "basic_vars = [\n",
    "    \"n_accommodates\",\n",
    "    \"n_beds\",\n",
    "    \"n_days_since\",\n",
    "    \"f_property_type\",\n",
    "    \"f_room_type\",\n",
    "    \"f_bathroom\",\n",
    "    \"f_cancellation_policy\",\n",
    "    \"f_bed_type\",\n",
    "    \"f_neighbourhood_cleansed\",\n",
    "]\n",
    "\n",
    "# reviews\n",
    "reviews = [\n",
    "    \"n_number_of_reviews\",\n",
    "    \"flag_n_number_of_reviews\",\n",
    "    \"n_review_scores_rating\",\n",
    "    \"flag_review_scores_rating\",\n",
    "]\n",
    "\n",
    "# dummy variables\n",
    "amenities = [col for col in df if col.startswith(\"d_\")]\n",
    "\n",
    "# interactions for the LASSO\n",
    "# from ch14\n",
    "X1 = [\n",
    "    \"n_accommodates:f_property_type\",\n",
    "    \"f_room_type:f_property_type\",\n",
    "    \"f_room_type:d_familykidfriendly\",\n",
    "    \"d_airconditioning:f_property_type\",\n",
    "    \"d_cats:f_property_type\",\n",
    "    \"d_dogs:f_property_type\",\n",
    "]\n",
    "# with boroughs\n",
    "X2 = [\n",
    "    \"f_property_type:f_neighbourhood_cleansed\",\n",
    "    \"f_room_type:f_neighbourhood_cleansed\",\n",
    "    \"n_accommodates:f_neighbourhood_cleansed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_1 = basic_vars\n",
    "predictors_2 = basic_vars + reviews + amenities\n",
    "predictors_E = basic_vars + reviews + amenities + X1 + X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data preparation we are using the [patsy](https://patsy.readthedocs.io/en/latest/overview.html) package (not [this](https://montypython.fandom.com/wiki/Patsy) Patsy, bur almost). `patsy` is a Python package for describing statistical models (especially linear models, or models that have a linear component) and building design matrices. It is closely inspired by and compatible with the formula mini-language used in R and S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dmatrices()` constructs two design matrices given a formula_like and data. By convention, the first matrix is the “outcome” or “y” data, and the second is the “predictor” or “x” data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.design_info.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('The theoretical recommended number of variables: {:.2f}.'.format(math.sqrt(len(X.design_info.column_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state = 20250224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_grid = {\"max_features\": [6, 8, 10, 12], \"min_samples_leaf\": [5, 10, 15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = GridSearchCV(\n",
    "    estimator = rfr,\n",
    "    param_grid = tune_grid,\n",
    "    cv = 5,\n",
    "    scoring = \"neg_root_mean_squared_error\",\n",
    "    verbose = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridsearchCV()` is an exhaustive search over specified parameter values for an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_model = rf_random.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Cross-validated results are saved in the grid search object's `cv_results_` attribute. Note that *RMSE* is displayed as a negative number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_rf_model_cv_results = pd.DataFrame(rf_model.cv_results_)[[\n",
    "    'param_max_features', 'param_min_samples_leaf', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_model_cv_results.columns = ['max features', 'min node size', 'RMSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_rf_model_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_rf_model_cv_results.pivot(\n",
    "    index = 'max features', \n",
    "    columns = 'min node size', \n",
    "    values = 'RMSE').round(2)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h, X_h = dmatrices(\"price ~ \" + \" + \".join(predictors_2), df_holdout)\n",
    "pred = rf_model.predict(X_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools.eval_measures import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(y_h, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_h, pred, squared= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***individual***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    rf_model.best_estimator_.feature_importances_, \n",
    "    X.design_info.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_var_imp = pd.DataFrame(\n",
    "    rf_model.best_estimator_.feature_importances_, \n",
    "    X.design_info.column_names)\\\n",
    "    .reset_index()\\\n",
    "    .rename({\"index\": \"variable\", 0: \"imp\"}, axis=1)\\\n",
    "    .sort_values(by=[\"imp\"], ascending=False)\\\n",
    "    .reset_index(drop = True)\n",
    "\n",
    "df_var_imp['cumulative_imp'] = df_var_imp['imp'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_var_imp.style.format({\n",
    "    'imp': lambda x: f'{x:,.1%}',\n",
    "    'cumulative_imp': lambda x: f'{x:,.1%}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Plotting var imp per se results in a nasty chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_var_imp\\\n",
    "    .sort_values(by = 'imp')\\\n",
    "    .plot(kind = 'barh', \n",
    "          x = 'variable', y = 'imp', \n",
    "          figsize = (10,10), grid = True, \n",
    "          title = 'Random forest model highest feature importances', \n",
    "          xlabel = 'variables', legend = False\n",
    "         );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only care for variables with an importance of more than 1 pct\n",
    "cutoff = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_var_imp[df_var_imp.imp > cutoff]\\\n",
    "    .sort_values(by = 'imp')\\\n",
    "    .plot(kind = 'barh', \n",
    "          x = 'variable', y = 'imp', \n",
    "          figsize = (10,6), grid = True, \n",
    "          title = 'Random forest model highest feature importances', \n",
    "          xlabel = 'variables', legend = False\n",
    "         );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting x-axis lables as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_var_imp[df_var_imp.imp > cutoff]\\\n",
    "    .sort_values(by = 'imp')\\\n",
    "    .plot(kind = 'barh',\n",
    "          x = 'variable', \n",
    "          y = 'imp',\n",
    "          figsize = (10,6), \n",
    "          grid = True,\n",
    "          title = 'Random forest model highest feature importances',\n",
    "          xlabel = 'variables', \n",
    "          legend = False)\n",
    "\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Grouped variable importance - keep binaries created off factors together***\n",
    "\n",
    "For this, you need to create an `sklearn` Pipeline including `OneHotEncoding` (before, encoding was done by patsy's `dmatrices`). This way permutation_importance can calculate factor variables' importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [(\"cat\", categorical_encoder, categorical_columns),\n",
    "    (\"num\", \"passthrough\", numerical_columns)])\n",
    "\n",
    "rf_pipeline = Pipeline(\n",
    "    [(\"preprocess\", preprocessing), \n",
    "     (\"regressor\", rf_model.best_estimator_)] # put best model to pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_pipeline.fit(df_train[predictors_2],df_train.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Permutation feature importance` overcomes limitations of the impurity-based feature importance: **they do not have a bias toward high-cardinality features** and can be computed on a left-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result = permutation_importance(\n",
    "    rf_pipeline,\n",
    "    df_holdout[predictors_2],\n",
    "    df_holdout.price,\n",
    "    n_repeats=10,\n",
    "    random_state=45,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "        result.importances_mean,\n",
    "        df_train[predictors_2].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = [\n",
    "    \"f_bed_type\",\n",
    "    \"f_property_type\",\n",
    "    \"f_room_type\",\n",
    "    \"f_bathroom\",\n",
    "    \"n_days_since\",\n",
    "    \"n_accommodates\",\n",
    "    \"n_beds\",\n",
    "    \"f_neighbourhood_cleansed\",\n",
    "    \"f_cancellation_policy\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_grouped_var_imp = pd.DataFrame(\n",
    "        result.importances_mean,\n",
    "        df_train[predictors_2].columns)\\\n",
    "    .loc[grouped]\\\n",
    "    .sort_values(by = 0, ascending = False)\\\n",
    "    .reset_index()\\\n",
    "    .rename({'index': 'variable', 0: 'imp'}, axis = 1)\n",
    "df_grouped_var_imp['cumulative_imp'] = df_grouped_var_imp.imp.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_grouped_var_imp.style.format({\n",
    "    'imp': lambda x: f'{x:,.1%}',\n",
    "    'cumulative_imp': lambda x: f'{x:,.1%}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_grouped_var_imp\\\n",
    "    .sort_values(by = 'imp')\\\n",
    "    .plot(kind = 'barh', \n",
    "          x = 'variable', y = 'imp', \n",
    "          figsize = (10,6), grid = True, \n",
    "          title = 'Random forest model grouped feature importances', \n",
    "          xlabel = 'variables', legend = False\n",
    "         )\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals = 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_clean_varimp = pd.DataFrame(\n",
    "        result.importances_mean,\n",
    "        df_train[predictors_2].columns)\\\n",
    "    .sort_values(by = 0, ascending = False)\\\n",
    "    .reset_index()\\\n",
    "    .rename({'index': 'variable', 0: 'imp'}, axis = 1)\n",
    "\n",
    "df_clean_varimp['cumulative_imp'] = df_var_imp['imp'].cumsum()\n",
    "df_clean_varimp[df_clean_varimp.cumulative_imp < 0.91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = df_clean_varimp.iloc[0:10]\\\n",
    "    .sort_values(by = 'imp')\\\n",
    "    .plot(kind = 'barh', \n",
    "          x = 'variable', y = 'imp', \n",
    "          figsize = (10,6), grid = True, \n",
    "          title = 'Random forest model top 10 feature importances with grouped variables', \n",
    "          xlabel = 'variables', legend = False\n",
    "         )\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals = 0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial dependence plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note: easy way, sklearn has plot_partial_dependence function we do this on holdout set!   \n",
    "Also, note that we run it not on the `rf_model` but on the `rf_pipeline` to manage OneHot_Encoding on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accomodates_pdp = partial_dependence(\n",
    "    rf_pipeline, df_holdout[predictors_2], [\"n_accommodates\"], kind=\"average\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accomodates_pdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to access the elements of this complex data structure\n",
    "type(accomodates_pdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {'number of accomodates': accomodates_pdp['values'][0], \n",
    "     'average price': accomodates_pdp['average'][0]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do our pdp plots using Pandas built-in plot method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {'number of accomodates': accomodates_pdp['values'][0], \n",
    "     'average price': accomodates_pdp['average'][0]}\n",
    "    ).sort_values(by = 'average price').plot(\n",
    "    kind = 'line', color = 'k', marker = 'o', markersize = 10, linewidth = 0,\n",
    "    figsize = (10,6), legend = False, grid = True,\n",
    "    x = 'number of accomodates', y = 'average price', ylim = (0, 140), \n",
    "    title = 'Partial dependence plot: number of accomodates'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` has its own visualization with complicated syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PartialDependenceDisplay(\n",
    "    pd_results = [accomodates_pdp],\n",
    "    features = [(0,)], \n",
    "    feature_names = df_holdout[predictors_2].columns.tolist(), \n",
    "    target_idx = 0,\n",
    "    deciles = {0: np.linspace(1, 7, num=7)}\n",
    ")\n",
    "display.plot()\n",
    "plt.title('Partial dependence plot for n_accomodates')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomtype_pdp = partial_dependence(\n",
    "    rf_pipeline, df_holdout[predictors_2], [\"f_room_type\"], kind=\"average\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {'room type': roomtype_pdp['values'][0], \n",
    "     'average price': roomtype_pdp['average'][0]}\n",
    "    ).sort_values(by = 'average price').plot(\n",
    "    kind = 'line', color = 'k', marker = 'o', markersize = 10, linewidth = 0,\n",
    "    figsize = (6,5), legend = False, grid = True,\n",
    "    x = 'room type', y = 'average price', ylim = (0, 140), \n",
    "    title = 'Partial dependence plot: room type'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsample performance: RMSE / mean(y) \n",
    "\n",
    "NOTE:  we do this on the holdout set, using the encoding pipeline `rf_pipeline` again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_w_prediction = df_holdout.assign(\n",
    "    predicted_price=rf_pipeline.predict(df_holdout[predictors_2])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Creating tables of heterogeneity by various grouping factors***\n",
    "- apartman size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_w_prediction['is_low_size'] = df_holdout_w_prediction.n_accommodates.map(lambda x: 'small apt' if x < 3 else 'large apt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_w_prediction.iloc[0:5, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_holdout_w_prediction.groupby('is_low_size').apply(lambda x: mean_squared_error(x.predicted_price, x.price, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it in a function with additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(groupby_obj):\n",
    "    return (\n",
    "        groupby_obj.apply(\n",
    "            lambda x: mean_squared_error(x.predicted_price, x.price, squared=False),\n",
    "        )\n",
    "        .to_frame(name=\"rmse\")\n",
    "        .assign(mean_price=groupby_obj.apply(lambda x: np.mean(x.price)).values)\n",
    "        .assign(rmse_normalized=lambda x: x.rmse / x.mean_price).round(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cheaper or more expensive flats - not used in book\n",
    "grouped_object = df_holdout_w_prediction.assign(\n",
    "    is_low_size=lambda x: np.where(x.n_accommodates <= 3, \"small apt\", \"large apt\")\n",
    ").groupby(\"is_low_size\")\n",
    "accom_subset = calculate_rmse(grouped_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accom_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fancy neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_object = df_holdout_w_prediction.loc[\n",
    "    lambda x: x.f_neighbourhood_cleansed.isin(\n",
    "        [\n",
    "            \"Westminster\",\n",
    "            \"Camden\",\n",
    "            \"Kensington and Chelsea\",\n",
    "            \"Tower Hamlets\",\n",
    "            \"Hackney\",\n",
    "            \"Newham\",\n",
    "        ]\n",
    "    )\n",
    "].groupby(\"f_neighbourhood_cleansed\")\n",
    "neightbourhood_subset = calculate_rmse(grouped_object)\n",
    "\n",
    "neightbourhood_subset.sort_values(by = 'mean_price', ascending = False).style.format({'rmse': '{:.1f}', 'mean_price': '{:.1f}', 'rmse_normalized': '{:.2f}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- property type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_object = df_holdout_w_prediction.loc[\n",
    "    lambda x: x.f_property_type.isin([\"Apartment\", \"House\"])\n",
    "].groupby(\"f_property_type\")\n",
    "proptype_subset = calculate_rmse(grouped_object)\n",
    "\n",
    "proptype_subset.style.format({'rmse': '{:.1f}', 'mean_price': '{:.1f}', 'rmse_normalized': '{:.2f}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_holdout = pd.DataFrame(\n",
    "    [\n",
    "        mean_squared_error(\n",
    "            df_holdout_w_prediction.price,\n",
    "            df_holdout_w_prediction.predicted_price,\n",
    "            squared=False,\n",
    "        ),\n",
    "        df_holdout_w_prediction.price.mean(),\n",
    "    ],\n",
    "    index=[\"rmse\", \"mean_price\"],\n",
    ").T.assign(rmse_normalized=lambda x: x.rmse / x.mean_price).round(2)\n",
    "all_holdout.index = [\"Total\"]\n",
    "\n",
    "all_holdout.style.format({'rmse': '{:.1f}', 'mean_price': '{:.1f}', 'rmse_normalized': '{:.2f}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_rows = pd.DataFrame(\n",
    "    None,\n",
    "    index=[\"Apartment size\", \"Type\", \"Borough\", \"------\"],\n",
    "    columns=[\"rmse\", \"mean_price\", \"rmse_normalized\"],\n",
    ").fillna(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally: subsample performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        type_rows.iloc[[0]],\n",
    "        accom_subset,\n",
    "        type_rows.iloc[[1]],\n",
    "        proptype_subset,\n",
    "        type_rows.iloc[[2]],\n",
    "        neightbourhood_subset,\n",
    "        type_rows.iloc[[3]],\n",
    "        all_holdout,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horserace: compare with other models \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ***OLS with dummies for area***\n",
    "\n",
    " using model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), df_train)\n",
    "\n",
    "ols_model = LinearRegression().fit(X,y)\n",
    "\n",
    "#y_test, X_test = dmatrices(\"price ~ \" + \" + \".join(predictors_2), df_holdout)\n",
    "\n",
    "y_hat = ols_model.predict(X)\n",
    "\n",
    "ols_rmse = mean_squared_error(y,y_hat,squared=False)\n",
    "ols_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model_coeffs_df = pd.DataFrame(\n",
    "    ols_model.coef_.tolist()[0],\n",
    "    index=X.design_info.column_names,\n",
    "    columns=[\"ols_coefficient\"],\n",
    ").assign(ols_coefficient=lambda x: x.ols_coefficient.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ols_model_coeffs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  LASSO\n",
    "\n",
    "using extended model w interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ElasticNet` model is combines L1 (LASSO) and L2 (Ridge) in a single class. \n",
    "\n",
    "The parameter `l1_ratio` (between [0,1]) is the weight of LASSO and Ridge. l1_ratio = 1 is the pure lasso penalty. Currently, l1_ratio <= 0.01 is not reliable, unless you supply your own sequence of alpha.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model =  ElasticNet(l1_ratio = 1, fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model_cv = GridSearchCV(\n",
    "    lasso_model,\n",
    "    # {\"alpha\":[i/100 for i in range(1, 26, 1)]}, #> this option takes forever to run\n",
    "    {\"alpha\":[i/100 for i in range(5, 26, 5)]},\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_E), df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lasso_model_cv.fit(X_scaled, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lasso_model_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lasso_rmse = pd.DataFrame(lasso_model_cv.cv_results_).loc[\n",
    "    lambda x: x.param_alpha == lasso_model_cv.best_estimator_.alpha\n",
    "].mean_test_score.values[0] * -1\n",
    "lasso_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ***CART model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model = DecisionTreeRegressor(random_state=20250224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get potential ccp_alpha parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = cart_model.cost_complexity_pruning_path(X, y.ravel())\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting. This algorithm is parameterized by \n",
    " known as the complexity parameter. The complexity parameter is used to define the cost-complexity measure.\n",
    "\n",
    "<center>\n",
    " $R_a(T) = R(T) + \\alpha(\\hat{T})$   \n",
    "</center>\n",
    " \n",
    " where $R(T)$ is the cost-complexity measure, and $\\alpha(\\hat{T})$ is the number of terminal nodes of tree $T$. \n",
    "\n",
    " By defalut `DecisionTreeRegressor` uses `squared error` as criterion for goodness-of-fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccp_alphas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impurities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply random search to select a \"best\" alpha, default is 10 iterations\n",
    "`RandomizedSearchCV` does not calculate all potential alphas, just a random 10-element subset of the many potential alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cart_model_cv = RandomizedSearchCV(\n",
    "    cart_model,\n",
    "    {\"ccp_alpha\":ccp_alphas},\n",
    "    cv = 5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose = 3,\n",
    ")\n",
    "cart_model_cv.fit(X,y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cart_rmse = pd.DataFrame(cart_model_cv.cv_results_).loc[\n",
    "    lambda x: x.param_ccp_alpha == cart_model_cv.best_estimator_.ccp_alpha\n",
    "].mean_test_score.values[0] * -1\n",
    "cart_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. GBM\n",
    "\n",
    "**NOTE:** With complex grid search run for a **very long time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingRegressor(learning_rate=0.1, min_samples_split=20, max_features = 10\n",
    "                                #, n_estimators = 50\n",
    "                               )\n",
    "\n",
    "tune_grid = {\"n_estimators\": [200, 300], \"max_depth\": [5, 10]}\n",
    "\n",
    "gbm_model_cv = GridSearchCV(\n",
    "    gbm,\n",
    "    tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbm_pipe = Pipeline(\n",
    "    [(\"preprocess\", preprocessing), (\"regressor\", gbm_model_cv)], verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gbm_pipe.fit(df_train[predictors_2],df_train.price)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gbm_model_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_rmse = gbm_model_cv.best_score_*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbm_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing model results on CV RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'model': ['OLS', 'LASSO', 'CART', 'random forest', 'GBM'],\n",
    "              'CV RMSE': [ols_rmse, lasso_rmse, cart_rmse, all_holdout.rmse[0], gbm_rmse]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Histogram-based Gradient Boosting Regression Tree***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram-based Gradient Boosting Regression Tree. It is experimental so we need to enable experimental features first. This implementation is inspired by [LightGBM](https://github.com/Microsoft/LightGBM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbm_broad = HistGradientBoostingRegressor(random_state = 20250224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tune_grid = {\n",
    "    \"max_iter\": [50, 100, 200],\n",
    "    \"max_depth\": [1, 5, 10],\n",
    "    \"learning_rate\": [0.1, 0.15, 0.2],\n",
    "    \"min_samples_leaf\": [5, 10, 20, 30],\n",
    "}\n",
    "\"\"\"\n",
    "# for the sake of simplicity we run on only a restricted tuning set on class\n",
    "tune_grid = {\n",
    "    # \"max_iter\": [50, 100, 200],\n",
    "    \"max_iter\": [200],\n",
    "    # \"max_depth\": [1, 5, 10],\n",
    "    \"max_depth\": [5, 10],\n",
    "    # \"learning_rate\": [0.1, 0.15, 0.2],\n",
    "    \"learning_rate\": [0.1, 0.15],\n",
    "    \"min_samples_leaf\": [10, 20],\n",
    "}\n",
    "\n",
    "hgbm_model_cv_broad = GridSearchCV(\n",
    "    hgbm_broad,\n",
    "    tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hgbm_pipe_broad = Pipeline(\n",
    "    [(\"preprocess\", preprocessing), (\"regressor\", hgbm_model_cv_broad)], verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "hgbm_pipe_broad.fit(df_train[predictors_2],df_train.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hgbm_model_cv_broad.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Broad HGBM RMSE is: {:.4f}.'.format(hgbm_model_cv_broad.best_score_*-1))\n",
    "print('Simple GBM RMSE is: {:.4f}.'.format(gbm_model_cv.best_score_*-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
