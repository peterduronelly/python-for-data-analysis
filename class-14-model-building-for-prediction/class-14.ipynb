{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Class 14: Model Building using LASSO </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.pardir, 'data', 'airbnb_hackney_workfile.csv') # this will produce a path with the right syntax for your operating system\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA IMPORT - FROM FILE\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where do we have missing variables now?\n",
    "to_filter=df.isna().sum()\n",
    "to_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_filter[to_filter>0].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_filter[to_filter>0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. drop if no target (already did)\n",
    "df.dropna(subset=['price'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. imput when few, not that important\n",
    "df['n_bathrooms']=df['n_bathrooms'].fillna(np.nanmedian(df['n_bathrooms'])) # !!! compute the median along the specified axis, while ignoring NaNs.\n",
    "df['n_beds']=df['n_beds'].fillna(df['n_accommodates'])\n",
    "df['f_bathroom']=df['f_bathroom'].fillna(1)\n",
    "df['f_minimum_nights']=df['f_minimum_nights'].fillna(1)\n",
    "df['f_number_of_reviews']=df['f_number_of_reviews'].fillna(1)\n",
    "df['ln_beds']=df['ln_beds'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_bathrooms'].describe().map('{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. drop columns when many missing not important\n",
    "df=df.drop([\"usd_cleaning_fee\", \"p_host_response_rate\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where do we have missing variables now?\n",
    "to_filter=df.isna().sum()\n",
    "to_filter[to_filter>0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [\"flag_days_since\",\"flag_review_scores_rating\",\"flag_reviews_per_month\"]:\n",
    "    df[var]=[int(x) for x in df[var.replace('flag','n')].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flag_days_since'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Replace missing variables re reviews with zero, when no review + add flags\n",
    "df['n_days_since']=df['n_days_since'].fillna(np.nanmedian(df['n_days_since']))\n",
    "df['n_review_scores_rating']=df['n_review_scores_rating'].fillna(np.nanmedian(df['n_review_scores_rating']))\n",
    "df['n_reviews_per_month']=df['n_reviews_per_month'].fillna(np.nanmedian(df['n_reviews_per_month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.flag_days_since.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at data\n",
    "df.price.describe().map('{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where do we have missing variables now?\n",
    "to_filter=df.isna().sum()\n",
    "to_filter[to_filter>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Business logic- define our prediction problem\n",
    "###################################\n",
    "# Decision\n",
    "# Size, we need a normal apartment, 1-7persons\n",
    "df=df.loc[df.n_accommodates < 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How is the average price changing in my district by `property_type`, `room_type` and the `bed_type`?\n",
    "df.groupby([\"f_property_type\", \"f_room_type\"]).agg(\n",
    "    mean_price=(\"price\", np.mean), \n",
    "    count = ('price', 'size')\n",
    ").style.format({'mean_price': '{:,.2f}', 'count': '{:,.0f}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"f_bed_type\"]).agg(mean_price=(\"price\", np.mean)).map('{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price.describe().map('{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How are extreme prices distributed?\n",
    "df.price.quantile([0.75, 0.8, 0.9, 0.95, 0.99, 0.995]).map('{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pick USD 400, above which all observations are excluded in the charts below.\n",
    "dfu=df[df.price<400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative frequencies with matplotlib\n",
    "\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(dfu.price, bins = 16, density = True, rwidth = 0.9, color = 'steelblue')\n",
    "ax.set_xlabel('price in USD')\n",
    "# ax.grid()\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(xmax=0.1, decimals = 0))\n",
    "ax.set_title('Relative frequency of apartment prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative frequencies with matplotlib\n",
    "\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(dfu.ln_price, bins = 16, density = True, rwidth = 0.9, color = 'steelblue')\n",
    "# ax.set_xticks(range(0, df.price.max(), 2000))\n",
    "ax.set_xlabel('ln price in USD')\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(xmax=10, decimals = 0))\n",
    "ax.set_title('Relative frequency of logged apartment prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = dfu, x = 'f_room_type', y = 'price', orient = 'v', order = ['Entire home/apt', 'Private room', 'Shared room'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu.f_room_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = dfu, x = 'n_accommodates', y = 'price', orient = 'v')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu.n_accommodates.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling\n",
    "\n",
    "**Basic variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_lev = (\n",
    "    \"n_accommodates\",\n",
    "    \"n_beds\",\n",
    "    \"f_property_type\",\n",
    "    \"f_room_type\",\n",
    "    \"n_days_since\",\n",
    "    \"flag_days_since\",\n",
    ")\n",
    "basic_add = (\"f_bathroom\", \"f_cancellation_policy\", \"f_bed_type\")\n",
    "reviews = (\"f_number_of_reviews\", \"n_review_scores_rating\", \"flag_review_scores_rating\")\n",
    "poly_lev = (\"n_accommodates2\", \"n_days_since2\", \"n_days_since3\")\n",
    "# not use p_host_response_rate due to missing obs\n",
    "amenities = list(df.filter(regex=\"^d_.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interactions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_diff_by_variables(df, factor_var, dummy_var, factor_lab, dummy_lab):\n",
    "    # Calculate statistics same way as before\n",
    "    stats = df.groupby([factor_var, dummy_var]).agg(\n",
    "        Mean=(\"price\", np.mean), \n",
    "        sd=(\"price\", np.std), \n",
    "        size=(\"price\", \"size\")\n",
    "    )\n",
    "    stats[\"se\"] = stats[\"sd\"] / stats[\"size\"] ** (1/2)\n",
    "    stats[\"Mean_l\"] = stats[\"Mean\"] - (1.96 * stats[\"se\"])\n",
    "    stats[\"Mean_u\"] = stats[\"Mean\"] + (1.96 * stats[\"se\"])\n",
    "    stats = stats.drop([\"sd\", \"size\"], axis=1).reset_index()\n",
    "\n",
    "    # Create the plot using seaborn\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    plt.figure()\n",
    "    \n",
    "    # Create bar plot\n",
    "    ax = sns.barplot(\n",
    "        data=stats,\n",
    "        x=stats.columns[0],\n",
    "        y='Mean',\n",
    "        hue=stats.columns[1],\n",
    "        palette=['indianred', 'steelblue'],\n",
    "        ci=None\n",
    "    )\n",
    "\n",
    "    # Add error bars\n",
    "    for i, group in enumerate(stats[stats.columns[1]].unique()):\n",
    "        group_data = stats[stats[stats.columns[1]] == group]\n",
    "        x = np.arange(len(group_data))\n",
    "        \n",
    "        # Adjust x positions for dodge effect\n",
    "        if i == 1:\n",
    "            x = x + 0.2\n",
    "        else:\n",
    "            x = x - 0.2\n",
    "            \n",
    "        plt.errorbar(\n",
    "            x=x, \n",
    "            y=group_data['Mean'],\n",
    "            yerr=[(group_data['Mean'] - group_data['Mean_l']), \n",
    "                  (group_data['Mean_u'] - group_data['Mean'])],\n",
    "            fmt='none',\n",
    "            color='black',\n",
    "            capsize=3\n",
    "        )\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(factor_lab)\n",
    "    plt.ylabel('Mean Price')\n",
    "    \n",
    "    # Customize legend\n",
    "    plt.legend(\n",
    "        title=dummy_lab,\n",
    "        bbox_to_anchor=(0.5, 1.15),\n",
    "        loc='center',\n",
    "        ncol=2,\n",
    "        fontsize=10,\n",
    "        title_fontsize=10\n",
    "    )\n",
    "    \n",
    "    # Remove grid\n",
    "    ax.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "    return plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_diff_by_variables(df,\"f_room_type\",\"d_familykidfriendly\",\"Room type\", \"Family kid friendly\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancelation policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_diff_by_variables(df, \"f_cancellation_policy\", \"d_familykidfriendly\", \"Cancellation policy\", \"Family kid friendly\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_diff_by_variables(df, \"f_cancellation_policy\", \"d_tv\", \"Cancellation policy\", \"TV\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up property type: cat and dog lovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_diff_by_variables(df, \"f_property_type\", \"d_cats\", \"Property type\", \"Cats\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_diff_by_variables(df, \"f_property_type\", \"d_dogs\", \"Property type\", \"Dogs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummies, interactions suggested by graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = (\"f_room_type*f_property_type\",  \"f_room_type*d_familykidfriendly\")\n",
    "X2= (\"d_airconditioning*f_property_type\", \"d_cats*f_property_type\", \"d_dogs*f_property_type\")\n",
    "X3= \"(f_property_type + f_room_type + f_cancellation_policy + f_bed_type) * (\"+ \"+\".join(amenities) +\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modellev1=\"~ n_accommodates\"\n",
    "modellev2=\"~\"+\"+\".join(basic_lev)\n",
    "modellev3=\"~\"+\"+\".join(basic_lev)+\"+\"+\"+\".join(basic_add)+\"+\"+\"+\".join(reviews)\n",
    "modellev4=\"~\"+\"+\".join(basic_lev)+\"+\"+\"+\".join(basic_add)+\"+\"+\"+\".join(reviews)+\"+\"+\"+\".join(poly_lev)\n",
    "modellev5=\"~\"+\"+\".join(basic_lev)+\"+\"+\"+\".join(basic_add)+\"+\"+\"+\".join(reviews)+\"+\"+\"+\".join(poly_lev)+\"+\"+\"+\".join(X1)\n",
    "modellev6=\"~\"+\"+\".join(basic_lev)+\"+\"+\"+\".join(basic_add)+\"+\"+\"+\".join(reviews)+\"+\"+\"+\".join(poly_lev)+\"+\"+\"+\".join(X1)+\"+\"+\"+\".join(X2)\n",
    "modellev7=\"~\"+\"+\".join(basic_lev)+\"+\"+\"+\".join(basic_add)+\"+\"+\"+\".join(reviews)+\"+\"+\"+\".join(poly_lev)+\"+\"+\"+\".join(X1)+\"+\"+\"+\".join(X2)+\"+\"+\"+\".join(amenities)\n",
    "modellev8=\"~\"+\"+\".join(basic_lev)+\"+\"+\"+\".join(basic_add)+\"+\"+\"+\".join(reviews)+\"+\"+\"+\".join(poly_lev)+\"+\"+\"+\".join(X1)+\"+\"+\"+\".join(X2)+\"+\"+\"+\".join(amenities)+\"+\"+X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modellev3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressions with cross-validation\n",
    "\n",
    "**Split train & holdout for cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_size = round(0.2 * df.shape[0])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed to make results reproducable\n",
    "np.random.seed(20250217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work, df_holdout=train_test_split(df, test_size=smp_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.tools.eval_measures import mse,rmse\n",
    "k = KFold(n_splits=n_folds, shuffle=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_reg(formula, df, kfold, testdf, robustse=None):\n",
    "    regression_list = []\n",
    "    predicts_on_test = []\n",
    "    rsquared = []\n",
    "    rmse_list = []\n",
    "    rmse_list_test = []\n",
    "\n",
    "    # Calculating OLS for each fold\n",
    "\n",
    "    for train_index, test_index in k.split(df):\n",
    "        df_train, df_test = df.iloc[train_index, :], df.iloc[test_index, :]\n",
    "        if robustse is None:\n",
    "            model = smf.ols(formula, data = df_train).fit()\n",
    "        else:\n",
    "            model = smf.ols(formula, data = df_train).fit(cov_type=robustse)\n",
    "        regression_list += [model]\n",
    "        predicts_on_test += [model.predict(df_test)]\n",
    "        rsquared += [model.rsquared]\n",
    "\n",
    "        rmse_tr = pd.concat(\n",
    "            [df_train[\"price\"], model.predict(df_train)],\n",
    "            axis=1,\n",
    "            keys=[\"price\", \"predicted\"],\n",
    "        )\n",
    "        rmse_tr = rmse_tr[~rmse_tr.isna().any(axis=1)]\n",
    "\n",
    "        rmse_te = pd.concat(\n",
    "            [df_test[\"price\"], model.predict(df_test)],\n",
    "            axis=1,\n",
    "            keys=[\"price\", \"predicted\"],\n",
    "        )\n",
    "        rmse_te = rmse_te[~rmse_te.isna().any(axis=1)]\n",
    "\n",
    "        rmse_list += [rmse(rmse_tr[\"price\"], rmse_tr[\"predicted\"], axis=0)]\n",
    "        rmse_list_test += [rmse(rmse_te[\"price\"], rmse_te[\"predicted\"], axis=0)]\n",
    "    nvars = model.df_model\n",
    "\n",
    "    return {\n",
    "        \"regressions\": regression_list,\n",
    "        \"test_predict\": predicts_on_test,\n",
    "        \"r2\": rsquared,\n",
    "        \"rmse\": rmse_list,\n",
    "        \"rmse_test\": rmse_list_test,\n",
    "        \"nvars\": nvars,\n",
    "    }\n",
    "\n",
    "\n",
    "def summarize_cv(cvlist, stat=\"rmse\"):\n",
    "    result = pd.DataFrame(\n",
    "        {\"Model\" + str(x + 1): cvlist[x][stat] for x in range(len(cvlist))}\n",
    "    )\n",
    "    result[\"Resample\"] = [\"Fold\" + str(x + 1) for x in range(len(cvlist[0][\"rmse\"]))]\n",
    "    result = result.set_index(\"Resample\")\n",
    "    result = pd.concat([result, pd.DataFrame(result.mean(), columns=[\"Average\"]).T])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_list = []\n",
    "for i in [\n",
    "    modellev1,\n",
    "    modellev2,\n",
    "    modellev3,\n",
    "    modellev4,\n",
    "    modellev5,\n",
    "    modellev6,\n",
    "    modellev7,\n",
    "    modellev8,\n",
    "]:\n",
    "    cv_list += [cv_reg(\"price\" + i, df, k, \"HC0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_cv(cv_list).map('{:,.3f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE training vs test graph\n",
    "\n",
    "rmse_levels = {\"nvars\": [], \"var\": [], \"value\": []}\n",
    "for i in range(0, 8):\n",
    "    rmse_levels[\"nvars\"].append(int(cv_list[i][\"nvars\"]))\n",
    "    rmse_levels[\"var\"].append(\"RMSE Training\")\n",
    "    rmse_levels[\"value\"].append(pd.Series(cv_list[i][\"rmse\"]).mean())\n",
    "for i in range(0, 8):\n",
    "    rmse_levels[\"nvars\"].append(int(cv_list[i][\"nvars\"]))\n",
    "    rmse_levels[\"var\"].append(\"RMSE Test\")\n",
    "    rmse_levels[\"value\"].append(pd.Series(cv_list[i][\"rmse_test\"]).mean())\n",
    "df_rmse_levels = pd.DataFrame.from_dict(rmse_levels)\n",
    "df_rmse_levels[\"nvars2\"] = df_rmse_levels[\"nvars\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmse_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "ax = sns.lineplot(\n",
    "    x = [str(x) for x in df_rmse_levels['nvars2']], \n",
    "    y = df_rmse_levels['value'], \n",
    "    hue = df_rmse_levels['var'], marker = 'o',\n",
    "    palette = ['k', 'steelblue']\n",
    ")\n",
    "ax.set_title('Train & Test RMSE')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_xlabel('# of coefficients')\n",
    "ax.legend(fontsize = 8, title = None)\n",
    "ax.grid(linestyle = ':')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO\n",
    "\n",
    "**Doing LASSO the hard way (aka *'naive' grid search*)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_model_7 = \"(f_property_type + f_room_type + f_cancellation_policy + f_bed_type) * (d_24hourcheckin + d_airconditioning + d_breakfast + d_buzzerwirelessintercom + d_cabletv + d_carbonmonoxidedetector + d_cats + d_dogs + d_doorman + d_doormanentry + d_dryer + d_elevatorinbuilding + d_essentials + d_familykidfriendly + d_fireextinguisher + d_firstaidkit + d_freeparkingonpremises + d_freeparkingonstreet + d_gym + d_hairdryer + d_hangers + d_heating + d_hottub + d_indoorfireplace + d_internet + d_iron + d_keypad + d_kitchen + d_laptopfriendlyworkspace + d_lockonbedroomdoor + d_lockbox + d_otherpets + d_paidparkingoffpremises + d_petsallowed + d_petsliveonthisproperty + d_pool + d_privateentrance + d_privatelivingroom + d_safetycard + d_selfcheckin + d_shampoo + d_smartlock + d_smokedetector + d_smokingallowed + d_suitableforevents + d_tv + d_washer + d_washerdryer + d_wheelchairaccessible + d_wirelessinternet)\"\n",
    "vars_model_8 = modellev8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import patsy\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "y, X = patsy.dmatrices(\"price\" + vars_model_8, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=smp_size, random_state=10\n",
    ")\n",
    "\n",
    "lambdas = [i/100 for i in range(5, 100,5)]\n",
    "\n",
    "train_r_squared = np.zeros(len(lambdas))\n",
    "test_r_squared = np.zeros(len(lambdas))\n",
    "\n",
    "pred_num = X.shape[1]\n",
    "coeff_a = np.zeros((len(lambdas), pred_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for ind, i in enumerate(lambdas):\n",
    "    print(f\"Run: {str(ind).rjust(2)}, lambda: {i:.2f}, start: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    reg = Lasso(alpha = i, random_state= 20250217) # In Python, Lasso's lambda is called alpha. Why?\n",
    "    reg.fit(X_train, y_train)\n",
    "    results = cross_val_score(reg, X, y, cv=cv, scoring=\"r2\")\n",
    "\n",
    "    train_r_squared[ind] = reg.score(X_train, y_train)    \n",
    "    test_r_squared[ind] = reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_df = (\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"$R^2$ Test set\": test_r_squared,\n",
    "            \"$R^2$ Training set\": train_r_squared,\n",
    "            \"lambda\": lambdas,\n",
    "        }\n",
    "    )\n",
    "    .melt(id_vars=[\"lambda\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_df[\"variable\"] = r_squared_df[\"variable\"].astype(\"category\").cat.reorder_categories(\n",
    "    [\"$R^2$ Training set\", \"$R^2$ Test set\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot results using `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "ax = sns.lineplot(\n",
    "    data = r_squared_df, \n",
    "    x = 'lambda', y = 'value', hue = 'variable', \n",
    "    palette = ['k', 'steelblue'],\n",
    "    marker = 'o'\n",
    ")\n",
    "ax.set_title('Train & Test $R^2$')\n",
    "ax.set_ylabel('$R^2$')\n",
    "ax.set_xlabel('lambda')\n",
    "ax.set_xticks(lambdas[1::2])\n",
    "ax.legend(fontsize = 10, title = None, labelcolor = ['k', 'steelblue'], loc='upper right', bbox_to_anchor=(0.4, 0.7))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lam = pd.DataFrame(test_r_squared*100, columns=['R_squared'])\n",
    "df_lam['lambda'] = (lambdas)\n",
    "# returns the index of the row where column has maximum value.\n",
    "df_lam.loc[df_lam['R_squared'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_best = Lasso(alpha = df_lam.loc[df_lam['R_squared'].idxmax()]['lambda'])\n",
    "reg_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_best.coef_[reg_best.coef_>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_best.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_best.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f'{mean_squared_error(y_test, reg_best.predict(X_test)):,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LASSO using `GridSearch`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cross-validation strategies: https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "- RepeatedKFold: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold\n",
    "- scoring: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "- GridSearch: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,  X = patsy.dmatrices('price'+vars_model_8, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_model_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` not only searches for the best parameters, but also automatically fits a new model on the whole training dataset with the parameters that yielded the best cross-validation performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define model\n",
    "model = Lasso()\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits = 5, n_repeats = 1, random_state = 20250217)\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid[\"alpha\"] = np.arange(0.05, 1, 0.05)\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring=\"neg_root_mean_squared_error\", cv = cv, verbose= 3) # control your output with the 'verbose' option\n",
    "# perform the search\n",
    "results = search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE: {(results.best_score_ * -1):,.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.cv_results_['rank_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_level = smf.ols('price'+modellev3, data=df_work).fit(cov_type='HC0')\n",
    "model7_level = smf.ols('price'+modellev7, data=df_work).fit(cov_type='HC0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at holdout RMSE\n",
    "model7_level_work_predictions = pd.concat(\n",
    "    [df_work[\"price\"], model7_level.predict(df_work)],\n",
    "    axis=1,\n",
    "    keys=[\"price\", \"predicted\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7_level_work_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.iloc[-3:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7_level_work_predictions = model7_level_work_predictions[~model7_level_work_predictions.isna().any(axis=1)]\n",
    "model7_level_work_rmse = rmse(model7_level_work_predictions[\"price\"], model7_level_work_predictions[\"predicted\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7_level_work_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7_level_holdout_predictions = pd.concat(\n",
    "    [df_holdout[\"price\"], model7_level.predict(df_holdout)],\n",
    "    axis=1,\n",
    "    keys=[\"price\", \"predicted\"],\n",
    ")\n",
    "model7_level_holdout_predictions = model7_level_holdout_predictions[~model7_level_holdout_predictions.isna().any(axis=1)]\n",
    "model7_level_holdout_rmse = rmse(model7_level_holdout_predictions[\"price\"], model7_level_holdout_predictions[\"predicted\"], axis=0)\n",
    "print(\n",
    "    f\"RMSE work:{round(model7_level_work_rmse,2)}\",\n",
    "    \"\\t\",\n",
    "    f\"RMSE holdout:{model7_level_holdout_rmse:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charting fitted vs actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ylev=df_holdout['price']\n",
    "\"\"\"meanY=Ylev.mean()\n",
    "sdY=Ylev.std()\n",
    "meanY_m2SE = meanY -1.96 * sdY\n",
    "meanY_p2SE = meanY + 1.96 * sdY\n",
    "Y5p=Ylev.quantile(.05)\n",
    "Y95p=Ylev.quantile(.95)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the `statsmodels` API is kind of reticent in its documentation. So much about the [summary_frame()](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.PredictionResults.summary_frame.html#statsmodels.regression.linear_model.PredictionResults.summary_frame) method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7_level.get_prediction(df_holdout).summary_frame(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df frame with the real and predicted values\n",
    "df_diagnostic = model7_level.get_prediction(df_holdout).summary_frame(alpha=0.05)\n",
    "\n",
    "df_ = pd.concat(\n",
    "    [df_holdout[\"price\"], model7_level.predict(df_holdout)],\n",
    "    axis=1,\n",
    "    keys=[\"price\", \"predicted\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_[~df_.isna().any(axis=1)].reset_index(drop=True)\n",
    "df_diagnostic[\"Ylev\"] = df_[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.DataFrame.any()`: Return whether any element is True, potentially over an axis. \r\n",
    "Returns False unless there is at least one element within a series or along a Dataframe axis that is True or equivalent (e.g. non-zero or non-empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 300, df_diagnostic.shape[0])\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "ax = sns.scatterplot(\n",
    "    data=df_diagnostic, x=\"mean\", y=\"Ylev\",\n",
    "    s = 25, color = 'steelblue'\n",
    ")\n",
    "plt.plot(x,x, color = 'k')\n",
    "ax.set_xlim(0,300)\n",
    "ax.set_ylim(0,300)\n",
    "ax.set_ylabel('actual')\n",
    "ax.set_xlabel('predicted')\n",
    "ax.set_title('Actual vs predicted in USD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redo predicted values at 80% PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = model7_level.get_prediction(df_holdout).summary_frame(alpha=0.2)\n",
    "df_extra = pd.concat(\n",
    "    [\n",
    "        df_holdout[\"price\"],\n",
    "        df_holdout[\"n_accommodates\"],\n",
    "        model7_level.predict(df_holdout),\n",
    "    ],\n",
    "    axis=1,\n",
    "    keys=[\"price\", \"n_accommodates\", \"predicted\"],\n",
    ")\n",
    "df_extra = df_extra[~df_extra.isna().any(axis=1)].reset_index(drop=True)\n",
    "dt[\"n_accommodates\"] = df_extra[\"n_accommodates\"]\n",
    "dt[\"Ylev\"] = df_extra[\"price\"]\n",
    "dt[\"elev\"] = dt[\"Ylev\"] - dt[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnostic = model7_level.get_prediction(df_holdout).summary_frame(alpha=0.2)\n",
    "df_ = pd.concat(\n",
    "    [\n",
    "        df_holdout[\"price\"],\n",
    "        df_holdout[\"n_accommodates\"],\n",
    "        model7_level.predict(df_holdout),\n",
    "    ],\n",
    "    axis=1,\n",
    "    keys=[\"price\", \"n_accommodates\", \"predicted\"],\n",
    ")\n",
    "df_ = df_[~df_.isna().any(axis=1)].reset_index(drop=True)\n",
    "df_diagnostic[\"n_accommodates\"] = df_[\"n_accommodates\"]\n",
    "df_diagnostic[\"Ylev\"] = df_[\"price\"]\n",
    "df_diagnostic[\"elev\"] = df_diagnostic[\"Ylev\"] - df_diagnostic[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionlev_holdout_summary = df_diagnostic.groupby(by=[\"n_accommodates\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionlev_holdout_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot bars for mean values\n",
    "ax.bar(predictionlev_holdout_summary['n_accommodates'],\n",
    "       predictionlev_holdout_summary['mean'],\n",
    "       color='steelblue',\n",
    "       alpha=0.7)\n",
    "\n",
    "# Plot error bars for observations\n",
    "ax.errorbar(predictionlev_holdout_summary['n_accommodates'],\n",
    "            predictionlev_holdout_summary['mean'],\n",
    "            yerr=[predictionlev_holdout_summary['mean'] - predictionlev_holdout_summary['obs_ci_lower'],\n",
    "                  predictionlev_holdout_summary['obs_ci_upper'] - predictionlev_holdout_summary['mean']],\n",
    "            fmt='none',\n",
    "            color='grey',\n",
    "            capsize=5,\n",
    "            capthick=3,\n",
    "            elinewidth=3)\n",
    "\n",
    "# Plot error bars for means\n",
    "ax.errorbar(predictionlev_holdout_summary['n_accommodates'],\n",
    "            predictionlev_holdout_summary['mean'],\n",
    "            yerr=[predictionlev_holdout_summary['mean'] - predictionlev_holdout_summary['mean_ci_lower'],\n",
    "                  predictionlev_holdout_summary['mean_ci_upper'] - predictionlev_holdout_summary['mean']],\n",
    "            fmt='bo',\n",
    "            color='k',\n",
    "            capsize=5,\n",
    "            capthick=3,\n",
    "            elinewidth=3)\n",
    "\n",
    "# Customize axes and labels\n",
    "ax.set_xlabel('Accommodates (Persons)')\n",
    "ax.set_ylabel('Predicted price (US dollars)')\n",
    "ax.set_title('Mean predictions and confidence intervals')\n",
    "\n",
    "# Set style similar to theme_bw()\n",
    "ax.grid(True, linestyle='-', alpha=0.2)\n",
    "ax.set_facecolor('white')\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_color('black')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Return the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
