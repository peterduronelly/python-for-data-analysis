{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Class 18: Forecasting Time Series</center>\n",
    "# <center>Part Two:  Stochastic Modelling</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import statsmodels\n",
    "import patsy\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pmdarima.arima import auto_arima\n",
    "except:\n",
    "    !pip install pmdarima\n",
    "    from pmdarima.arima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.pardir, 'data', 'homeprices-data-2000-2018.csv') # this will produce a path with the right syntax for your operating system\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA IMPORT - FROM FILE\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(date=lambda x: x.date.str[0:7])\n",
    "df = df.rename({\"pn\": \"p\", \"us\": \"u\", \"emps\": \"emp\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"date\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dp'] = df.p.diff(1)\n",
    "df['p_lag'] = df.p.shift(1)\n",
    "df['lnp'] = np.log(df.p)\n",
    "df['dlnp'] = df.lnp.diff(1)\n",
    "df['lnp_lag'] = df.lnp.shift(1)\n",
    "df['dlnp_lag'] = df.dlnp.shift(1)\n",
    "df['du'] = df.u.diff(1)\n",
    "df['lnemp'] = np.log(df.emp)\n",
    "df['dlnemp'] = df.lnemp.diff(1)\n",
    "df['trend'] = range(1, df.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (8,6))\n",
    "plt.plot(pd.to_datetime(df.date), df.p)\n",
    "plt.ylabel('Case-shiller Price index')\n",
    "plt.grid(True, linestyle = ':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log difference of price index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (8,6))\n",
    "plt.plot(pd.to_datetime(df.date), df.dp)\n",
    "plt.ylabel('first difference of the price index')\n",
    "plt.hlines(0, xmin = pd.to_datetime(df.date).min(), xmax = pd.to_datetime(df.date).max(), color = 'k')\n",
    "plt.grid(True, linestyle = ':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log difference of price index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (8,6))\n",
    "plt.plot(pd.to_datetime(df.date), df.dlnp)\n",
    "plt.ylabel('log first difference of the price index')\n",
    "plt.hlines(0, xmin = pd.to_datetime(df.date).min(), xmax = pd.to_datetime(df.date).max(), color = 'k')\n",
    "plt.grid(True, linestyle = ':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Employment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (8,6))\n",
    "plt.plot(pd.to_datetime(df.date), df.emp)\n",
    "plt.ylabel('employment (in thousands)')\n",
    "plt.grid(True, linestyle = ':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log diff employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (8,6))\n",
    "plt.plot(pd.to_datetime(df.date), df.dlnemp)\n",
    "plt.ylabel('log change in employment')\n",
    "plt.hlines(0, xmin = pd.to_datetime(df.date).min(), xmax = pd.to_datetime(df.date).max(), color = 'k')\n",
    "plt.grid(True, linestyle = ':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unemployment rate"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "u_plot = (\n",
    "    ggplot(data, aes(x=\"date\", y=\"u\", group=1))\n",
    "    + geom_line(color=color[0], size=1)\n",
    "    + scale_x_date(breaks=breaks(limits)[::3], labels=date_format(\"%b%Y\"))\n",
    "    + labs(y=\"Unemployment rate (percent)\", x=\"Date (month)\")\n",
    "    + theme_bw()\n",
    ")\n",
    "\n",
    "u_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (8,6))\n",
    "plt.plot(pd.to_datetime(df.date), df.u)\n",
    "plt.ylabel('unemployment rate (in pct)')\n",
    "plt.grid(True, linestyle = ':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unemployment 1st diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (8,6))\n",
    "plt.plot(pd.to_datetime(df.date), df.du)\n",
    "plt.ylabel('change in the unemployment rate')\n",
    "plt.hlines(0, xmin = pd.to_datetime(df.date).min(), xmax = pd.to_datetime(df.date).max(), color = 'k')\n",
    "plt.grid(True, linestyle = ':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create work set and holdout set\n",
    "\n",
    "- we start after the [GFC](https://en.wikipedia.org/wiki/2007%E2%80%932008_financial_crisis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create work and holdout sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout = df[df.year == 2018]\n",
    "df_work = df[df.year < 2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create training and test sets for 4 folds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2013, 2018):\n",
    "    fold = year - 2012\n",
    "    df_work[\"test\" + str(fold)] = df_work[\"year\"] == year\n",
    "    df_work[\"train\" + str(fold)] = (df_work[\"year\"] <= year - 1) & (\n",
    "        df_work[\"year\"] >= year - 13\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work[df_work.train1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work[df_work.test1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work[df_work.train2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work[df_work.test2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model M1: OLS on trend & seasonality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_1 = []\n",
    "for i in range(1, 5):\n",
    "\n",
    "    df_train = df_work.loc[lambda x: x[\"train\" + str(i)] == 1]\n",
    "    df_test = df_work.loc[lambda x: x[\"test\" + str(i)] == 1]\n",
    "\n",
    "    model1 = smf.ols(\"p ~ trend + C(month)\", df_train).fit()\n",
    "\n",
    "    phat = model1.predict(df_test)\n",
    "\n",
    "    errsq = np.square(df_test.p.values - phat)\n",
    "\n",
    "    mse_1.append(np.mean(errsq))\n",
    "\n",
    "rmse_cv_m1 = np.sqrt(np.mean(mse_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model M2: simple ARIMA(1,1,2)**\n",
    "\n",
    "- get order from auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m2 = auto_arima(\n",
    "    y = df_work.p,\n",
    "    start_p = 0,\n",
    "    max_p = 1,  # without this constrain, python returns a higher AR order\n",
    "    # max_order=0,\n",
    "    seasonal = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_2 = []\n",
    "\n",
    "for i in range(1, 5):\n",
    "\n",
    "    df_train = df_work.loc[lambda x: x[\"train\" + str(i)] == 1]\n",
    "    df_test = df_work.loc[lambda x: x[\"test\" + str(i)] == 1]\n",
    "\n",
    "    model2 = ARIMA(df_train.p, order=auto_arima_m2.get_params()[\"order\"]).fit()\n",
    "\n",
    "    phat = model2.forecast(steps=12)\n",
    "\n",
    "    errsq = np.square(df_test.p.values - phat)\n",
    "\n",
    "    mse_2.append(np.mean(errsq))\n",
    "\n",
    "rmse_cv_m2 = np.sqrt(np.mean(mse_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model M3: p ARIMA(1,1,0)**\n",
    "\n",
    "- get order from auto_arima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to create dummies with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df_work.month).iloc[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the backend calculations `numpy` cannot correctly handle booleans, so a type conversion is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df_work.month).iloc[0:12].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m3 = auto_arima(\n",
    "    y = df_work.p, \n",
    "    X = pd.get_dummies(df_work.month).astype(int), \n",
    "    seasonal = False,\n",
    "    start_p = 0,\n",
    "    max_p= 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m3.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_3 = []\n",
    "for i in range(1, 5):\n",
    "\n",
    "    df_train = df_work.loc[lambda x: x[\"train\" + str(i)] == 1]\n",
    "    df_test = df_work.loc[lambda x: x[\"test\" + str(i)] == 1]\n",
    "\n",
    "    model3 = ARIMA(\n",
    "        df_train.p,\n",
    "        exog=pd.get_dummies(df_train.month),\n",
    "        order=auto_arima_m3.get_params()[\"order\"],\n",
    "    ).fit()\n",
    "\n",
    "    phat = model3.forecast(steps=12, exog=pd.get_dummies(df_test.month))\n",
    "\n",
    "    errsq = np.square(df_test.p.values - phat)\n",
    "\n",
    "    mse_3.append(np.mean(errsq))\n",
    "\n",
    "rmse_cv_m3 = np.sqrt(np.mean(mse_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model M4: p ARIMA(2,0,0) + seasonality + trend**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df_work.month).astype(int)\n",
    "X.columns = [str(x) for x in X.columns] # we need to convert numerical colnames to str as pmdarima cannot handle column names of mixed types\n",
    "X['trend'] = df_work.trend\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m4 = auto_arima(\n",
    "    y = df_work.p,\n",
    "    X = X,\n",
    "    seasonal = False,\n",
    "    start_p = 0,\n",
    "    max_p = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m4.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_4 = []\n",
    "for i in range(1, 5):\n",
    "\n",
    "    df_train = df_work.loc[lambda x: x[\"train\" + str(i)] == 1]\n",
    "    df_test = df_work.loc[lambda x: x[\"test\" + str(i)] == 1]\n",
    "\n",
    "    model4 = ARIMA(\n",
    "        df_train.p,\n",
    "        exog = pd.get_dummies(df_train.month).astype(int),\n",
    "        trend = 't', # 't' stands for a linear term\n",
    "        order = auto_arima_m4.get_params()[\"order\"],\n",
    "    ).fit()\n",
    "\n",
    "    phat = model4.forecast(steps=12, exog=pd.get_dummies(df_test.month), trend=\"t\")\n",
    "\n",
    "    errsq = np.square(df_test.p.values - phat)\n",
    "\n",
    "    mse_4.append(np.mean(errsq))\n",
    "\n",
    "rmse_cv_m4 = np.sqrt(np.mean(mse_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model M5: dp ~ month + trend, without any ARIMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_5 = []\n",
    "for i in range(1, 5):\n",
    "\n",
    "    df_train = df_work.loc[lambda x: x[\"train\" + str(i)] == 1]\n",
    "    df_test = df_work.loc[lambda x: x[\"test\" + str(i)] == 1]\n",
    "\n",
    "    model5 = smf.ols(\"dp ~ trend + C(month)\", df_train).fit()\n",
    "\n",
    "    dphat = model5.predict(df_test)\n",
    "\n",
    "    df_test[\"phat\"] = None\n",
    "    \n",
    "    for i in range(0, 12):\n",
    "        if i == 0:\n",
    "            df_test.iloc[i, -1] = df_train[\"p\"].values[-1] + dphat.iloc[i]\n",
    "        else:\n",
    "            df_test.iloc[i, -1] = df_test.iloc[i - 1, -1] + dphat.iloc[i]\n",
    "\n",
    "    errsq = np.square(df_test[\"p\"] - df_test[\"phat\"])\n",
    "\n",
    "    mse_5.append(np.mean(errsq))\n",
    "\n",
    "rmse_cv_m5 = np.sqrt(np.mean(mse_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_m5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model M6: lnp ARIMA(1,2,2) + built-in seasonality using `auto_arima`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m6 = auto_arima(\n",
    "    y = df_work.lnp,\n",
    "    d = 2,  # without this constrain, python returns other ARIMA order\n",
    "    seasonal=True,\n",
    "    m = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m6.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_6 = []\n",
    "for i in range(1, 5):\n",
    "\n",
    "    df_train = df_work.loc[lambda x: x[\"train\" + str(i)] == 1]\n",
    "    df_test = df_work.loc[lambda x: x[\"test\" + str(i)] == 1]\n",
    "\n",
    "    model6 = ARIMA(\n",
    "        df_train.lnp,\n",
    "        # exog=pd.get_dummies(df_train.month),\n",
    "        order=auto_arima_m6.get_params()[\"order\"],\n",
    "    ).fit()\n",
    "\n",
    "    lnphat = model6.forecast(steps=12, exog=pd.get_dummies(df_test.month))\n",
    "\n",
    "    corrb = mean_squared_error(df_test.lnp, lnphat)\n",
    "\n",
    "    phat = np.exp((lnphat + corrb / 2))\n",
    "\n",
    "    errsq = np.square(df_test.p.values - phat)\n",
    "\n",
    "    mse_6.append(np.mean(errsq))\n",
    "\n",
    "rmse_cv_m6 = np.sqrt(np.mean(mse_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_m6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vector Autoregression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_var = []\n",
    "for i in range(1, 5):\n",
    "\n",
    "    df_train = df_work.loc[lambda x: x[\"train\" + str(i)] == 1, :].dropna()\n",
    "    df_test = df_work.loc[lambda x: x[\"test\" + str(i)] == 1, :].dropna()\n",
    "\n",
    "    model7 = VAR(df_train[[\"dp\", \"du\", \"dlnemp\"]]).fit(1)\n",
    "\n",
    "    dphat = model7.forecast(\n",
    "        df_train[[\"dp\", \"du\", \"dlnemp\"]].values[-model7.k_ar :], steps=12\n",
    "    )[:, 0]\n",
    "\n",
    "    df_test[\"phat\"] = None\n",
    "    for i in range(0, 12):\n",
    "        if i == 0:\n",
    "            df_test.iloc[i, -1] = df_train[\"p\"].values[-1] + dphat[i]\n",
    "        else:\n",
    "            df_test.iloc[i, -1] = df_test.iloc[i - 1, -1] + dphat[i]\n",
    "\n",
    "    errsq = np.square(df_test[\"p\"] - df_test[\"phat\"])\n",
    "\n",
    "    mse_var.append(np.mean(errsq))\n",
    "\n",
    "rmse_cv_m7 = np.sqrt(np.mean(mse_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.k_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[[\"dp\", \"du\", \"dlnemp\"]].values[-model7.k_ar :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.forecast(\n",
    "        df_train[[\"dp\", \"du\", \"dlnemp\"]].values[-model7.k_ar :], steps=12\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.forecast(\n",
    "        df_train[[\"dp\", \"du\", \"dlnemp\"]].values[-model7.k_ar :], steps=12\n",
    "    )[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_m7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "*Note: some model's cv rmse differns from textbook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [mse_1, mse_2, mse_3, mse_4, mse_5, mse_6, mse_var],\n",
    "    columns=[\"Fold\" + str(i) for i in range(1, 5)],\n",
    ").apply(np.sqrt).assign(\n",
    "    Average=[\n",
    "        rmse_cv_m1,\n",
    "        rmse_cv_m2,\n",
    "        rmse_cv_m3,\n",
    "        rmse_cv_m4,\n",
    "        rmse_cv_m5,\n",
    "        rmse_cv_m6,\n",
    "        rmse_cv_m7,\n",
    "    ],\n",
    "    model=[\"M\" + str(i) for i in range(1, 7)] + [\"M7 (var)\"],\n",
    ").round(\n",
    "    2\n",
    ").set_index(\n",
    "    \"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best model is M4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m4.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What's inside the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auto_arima_m4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_m4.plot_diagnostics(figsize = (9,7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Re-estimate best models on full work set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = ARIMA(\n",
    "    df_work.p, \n",
    "    exog = pd.get_dummies(df_work.month).astype(int), \n",
    "    trend = \"t\", \n",
    "    order = auto_arima_m4.get_params()[\"order\"]\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_final.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final = model_final.get_forecast(\n",
    "    steps=12, \n",
    "    exog = pd.get_dummies(df_holdout.month).astype(int),\n",
    "    trend=\"t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_holdout_best = (\n",
    "    df_holdout.assign(\n",
    "        p_pred = pred_final.predicted_mean.values, \n",
    "        model=\"best\")\n",
    "    .join(pred_final.conf_int(alpha=0.2))\n",
    "    .filter([\"model\", \"p_pred\", \"lower p\", \"upper p\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_holdout_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.join(forecast_holdout_best).loc[lambda x: x.year >= 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (8,6))\n",
    "plt.plot(df_plot.date, df_plot.p, color = 'k')\n",
    "plt.plot(df_plot.date, df_plot.p_pred, color = 'darkblue', linestyle = '--')\n",
    "plt.fill_between(df_plot.date, df_plot['lower p'], df_plot['upper p'], color = 'indianred', alpha = 0.5)\n",
    "plt.legend(['actual', 'predicted', 'prediction interval'], loc = 'upper left', labelcolor = ['k', 'darkblue', 'indianred'])\n",
    "plt.ylabel('2000 = 100')\n",
    "plt.grid(True, linestyle = ':')\n",
    "plt.yticks(range(220,340,10))\n",
    "plt.title('Case-Shiller Home Price Index: Actual vs Prediction');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errsq = np.square(df_holdout.p.values - forecast_holdout_best.p_pred)\n",
    "\n",
    "rmse_holdout = np.mean(errsq)\n",
    "rmse_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
